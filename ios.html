<!doctype html>
<html lang="en">
<head>
    <title>Unrupt calls</title>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    <style>

        @media (min-height: 199.99px) and (min-width: 149.99px) {
            .video {
                width: 240px;
                height: 320px;
                background: greenyellow;
                margin: 0 auto;
            }

            h1 {
                font-size: 1.3em;
            }
        }


        @media (min-height: 699.99px) and (min-width: 299.99px) {
            .video {
                width: 240px;
                height: 604px;
                background: gold;
            }
        }

        @media (min-height: 650.99px) and (min-width: 350.99px) {
            .video {
                width: 309px;
                height: 550px;
                background: red;
            }
        }

        @media (min-height: 799.99px) and (min-width: 599.99px) {
            .video {
                width: 480px;
                height: 640px;
                background: goldenrod;

            }
        }
        @media (min-height: 1023.99px) and (min-width: 799.99px) {
            .video {
                width: 720px;
                height: 960px;
                background: darkgoldenrod;
            }
        }
        @media (min-height: 1299.99px) and (min-width: 999.99px) {
            .video {
                width: 960px;
                height: 1280px;
                background: darkolivegreen;
            }
        }

        #out {
            transform: rotateY(180deg);
            width:100%;
            position:absolute;
            left:0;
            right:0;
            bottom:0;
            margin:auto;
            background-size:contain;
            background-position: center;
        }

        #in {
            position: absolute;
            left:0px;
            bottom:0px;
            width: 96px;
            height: 128px;
        }


        #audioInfo {
            position: relative;

        }

        #otherUser {
            position: relative;

        }

        #chosenAction {
            clear: both;
            text-align: center;
        }


        .playpause {
            display: none;
            width:100%;
            position:absolute;
            left:0;
            right:0;
            bottom:0;
            margin:auto;
            background-size:contain;
            background-position: center;
            z-index: 99999;
        }
    </style>

</head>
<body>
<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" crossorigin="anonymous"></script>
<script src="https://pi.pe/iot/js/qrcode.js"></script>

<h1 id="title" class="text-center"><a target="_blank" href="https://docs.google.com/document/d/1UAAJUiSZ99gehOnBDvY33yO4yRx-voZ71OsuZrqpiDY/edit">Family Systems</a> <a href="ios.html">Unrupt Demo 1.0</a></h1>
    <div class="video" id="otherUser" onclick="doPlay();">
        <div id="pauseOther" class="playpause">
            <object data="pause.svg"></object>
        </div>
    </div>
<div class="container">
        <div class="progress">
            <div id="unruptbuffer_spk" class="progress-bar progress-bar-striped bg-warning" role="progressbar"
                 aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div>
            <div id="unruptbuffer_sil" class="progress-bar " role="progressbar" aria-valuenow="100"
                 aria-valuemin="0" aria-valuemax="100"></div>
        </div>
    <div>
        <span id="mode" class="badge badge-primary pull-left">Direct</span>
        <span id="unruptbuffer_len" class="badge pull-right"></span>
    </div>
    <div id="chosenAction">
        <button id="action" type="button" class="btn btn-primary btn-lg"><i class="fa fa-times-circle fa-2x" aria-hidden="true"></i></button>
        <button id="pause" type="button" class="btn btn-primary btn-lg"><i id="pauseIcon" class="fa fa-play-circle fa-2x" aria-hidden="true"></i></button>
        <button id="mute" type="button" class="btn btn-primary btn-lg"><i id="muteIcon" class="fa fa-microphone fa-2x" aria-hidden="true"></i></button>
        <button id="unruptToggle" type="button" class="btn btn-primary btn-lg"><i id="pwsIcon" class="fa fa-exchange fa-2x" aria-hidden="true"></i></button>
    </div>
</div>
<div id="share" class="modal" tabindex="-1" role="dialog">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Share this url to request a call</h5>
            </div>
            <div class="modal-body" id="shareQR">

            </div>
            <div class="modal-footer">
                <button id="shareDone" type="button" class="btn btn-secondary" data-dismiss="modal" onclick="shared();">Done</button>
            </div>
        </div>
    </div>
</div>
<div id="accept" class="modal" tabindex="-1" role="dialog">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Accept a call</h5>
            </div>
            <div class="modal-body">
                <p>Click 'accept' to start the call.</p>
            </div>
            <div class="modal-footer">
                <button id="callAccept" type="button" class="btn btn-secondary" data-dismiss="modal" onclick="accepted();">Accept</button>
            </div>
        </div>
    </div>
</div>

<!--script src="properties.js"></script-->
<script>
    var properties = {
        versionname :"Default", // update this to indicate which version of the settings this is
        procFramesize: 4096, // how many samples (at 44k1 Hz) in a frame. default 4096 ->  ~100ms
// this impacts the latency - but go too low and the audio will break up
        scopeFftSize : 2048, // number of samples in the FFT for the oscilloscope. default 2048 seems ok
        micSilenceThreshold : 0.0175, // minumum mean mic volume (in range of 0.0->1.0) of a frame that contains voice
// used to trigger pause/unpause
// default 0.0175 ok on imacs
        farSilenceThreshold : 0.0175, // minimum mean remote volume (in range of 0.0->1.0) of a frame that contains voice
// used to trim silence from playout
// default 0.0175 ok on imacs

        minFramesSilenceForPause: 15, // number of silent near frames (from mic) before we unpause and re-start playback.
        minFramesSilenceForPlay: 3,  // number of silent frames before we start to clip silence from playback. default 3 (300ms)
        maxStashFrames: 500, // longest possible pause (in frames). default 1000 -> 100 sec
        websocketURL: "wss://pi.pe/websocket/?finger=" // where to find the redezvous server.
    };



    var webRTCconfiguration = {
        "iceServers": [
            {urls: "stun:146.148.121.175:3478"},
            {urls: "turn:146.148.121.175:3478?transport=udp", 'credential': 'nexus5x', 'username': 'smartphone'},
        ],
        "bundlePolicy":"max-bundle","iceCandidatePoolSize":1
    };



    var pc; // actual peer connection to our friend
    var socket; // used to set up connection with our peer.
    var mid;
    var fid;
    var cid;
    var myac;
    var yourac;
    var yourBuffer;
    var myBuffer;
    var initiator;
    var lcandyStash = [];
    var rcandyStash = [];
    var localStream;
    var remoteStream;
    var scopes= [];
    var procs = [];
    var backlog = 0;
    var backlog_sil = 0;
    var backlog_spk = 0;
    var tick;
    var iamspeaking = false;
    var mute = false;
    var paused = false;
    var videoEnabled = false;
    var peerConnectionOfferAnswerCriteria =  {offerToReceiveAudio: true, offerToReceiveVideo: false };
    var unruptEnabled = true;
    var toggleUnrupt;
    var AudioContext = window.AudioContext || window.webkitAudioContext;
    var framecount =0;
    var mode = "waiting";
    var offerSendLoop
    var session;

    // message stuff - used to create direct connection to peer over WEBRTC

    function messageDeal(event){
        //console.log("message is ", event.data);
        var data = JSON.parse(event.data);
        console.log("message data is ", data);
        if (data.to != mid){
            alert("message mixup");
        }
        switch (data.type) {
            case "cheatUnruptToggle":
                toggleUnrupt();
                break;
            case "offer":
                if (pc) {
                    if (session == null) {
                        session = data.session;
                    } else {
                        console.log("we got a duplicate offer ?!?")
                    }
                    if (fid == null) {
                        fid = data.from;
                    }
                    pc.setRemoteDescription(data).then(_ =>
                        pc.createAnswer(peerConnectionOfferAnswerCriteria).then(ans =>
                            pc.setLocalDescription(ans).then(_ =>
                                sendMessage(fid, mid, "answer", ans.sdp)
                            )
                        )
                    )
                        .catch((e) => console.log("set Remote offer error", e));
                } else {
                    console.log("not ready yet, no pc created.");
                }
                break;
            case "answer":
                if ((session) && (session === data.session)) {
                    window.clearInterval(offerSendLoop);
                    pc.setRemoteDescription(data)
                        .then(_ => {
                            //$("#action").text("hangup");
                        })
                        .catch(e => console.log("set Remote answer error", e));
                } else {
                    console.log("Got answer we were not expecting. Session was "+session+" data.session was "+data.session);
                    alert("Mixup in sessions for answer");
                }
                break;
            case "candidate":
                if ((session) && (session === data.session)) {
                    var jc = {
                        sdpMLineIndex: 0,
                        candidate: data.sdp
                    };
                    console.log("adding candidate ", jc);
                    var nc = new RTCIceCandidate(jc);
                    pc.addIceCandidate(nc)
                        .then(_ => console.log("added remote candidate"))
                        .catch((e) => console.log("couldn't add candidate ", e));
                } else {
                    console.log("Session error for candidates. Session was "+session+" data.session was "+data.session);
                }
                break;
        }
    }

    function sendJ(m){
        var message = JSON.stringify(m);
        console.log("sending ", m);
        socket.send(message);
    }
    function sendMessage(to,from,type,data){

        var messageJ = {
            to:to,
            retry:0,
            from:from,
            type:type,
            sdp:data
        };
        if (type==='offer') {
            messageJ.retry = 5;
            session = Date.now();
            messageJ.session = session;
            offerSendLoop = window.setInterval((it) => {
                if (messageJ.retry > 0) {
                    messageJ.retry--;
                    sendJ(messageJ);
                } else {
                    window.clearInterval(offerSendLoop);
                    console.log("given up on ", messageJ);
                }
            }, 10000);
        } else {
            messageJ.session = session;
        }
        // so either way we send it once _immediately_
        // offers we keep sending for a minute - 'till we see an answer or....
        sendJ(messageJ);
    }

    // button actions

    function startCall(cid){
        lcandyStash = [];
        rcandyStash = [];
        fid = cid;
        pc.createOffer(peerConnectionOfferAnswerCriteria)
            .then(desc => {
                console.log("offer created",);
                pc.setLocalDescription(desc).then( d => sendMessage(fid, mid, desc.type, desc.sdp));
            })
            .catch(e => console.log("offer not created due to ", e) );
    }

    function stopCall(){
        window.location.href = window.location.href;
    }

    function videoCapture() {
        var video = document.getElementById("out");
        var videoWidth = video.videoWidth, videoHeight = video.videoHeight;
        var canvas = document.getElementById('pauseOther');
        canvas.width = videoWidth;
        canvas.height = videoHeight;
        var context = canvas.getContext('2d');
        context.translate(canvas.width, 0);

        // flip context horizontally
        context.scale(-1, 1);

        context.drawImage(
            video, 0, 0, videoWidth, videoHeight
        );

        var img = new Image();
        img.onload = function() {
            context.drawImage(img, (videoWidth/2)-24, (videoHeight/2)-24);
        }
        img.src = "pause.svg";
    }
    // webaudio processing

    // display waveform for diagnostics
    function doScopeNode(ac, node, scopename) {
        console.log("making scope node ", scopename);
        var analyser = ac.createAnalyser();
        analyser.fftSize = properties.scopeFftSize;
        node.connect(analyser);
        makeDraw(scopename, analyser);
        scopes.push(analyser);
        return analyser;
    }

    // processing incoming audio
    function yourProc(node){
        var buffer = yourBuffer;
        console.log("made unrupt buffer of size ", buffer.bufferSize, buffer);
        var silentcount = 0;
        var audiostash = [];

        var ub = $('#unruptToggle');

        var pb = $("#pause");

        console.log('PauseButton!!!', pb);

        var oldmute = false;

        toggleUnrupt = () => {
            var ubi = $('#pwsIcon');
            if (unruptEnabled) {
                unruptEnabled = false;
                console.log('disconnecting the buffer');
                node.disconnect(buffer);
                document.getElementById('out').muted = false;
                document.getElementById('out').play();
                $('#pauseOther').hide();
                ubi.removeClass("fa-exchange");
                ubi.addClass("fa-arrows-h");
            } else {
                unruptEnabled = true;
                console.log('connecting the buffer');
                node.connect(buffer);
                document.getElementById('out').muted = true;
                ubi.removeClass("fa-arrows-h");
                ubi.addClass("fa-exchange");
            }
        }


        ub.off('click').on('click', (e) => {
            e.stopImmediatePropagation();
            toggleUnrupt();
            sendMessage(fid, mid, "cheatUnruptToggle", true);
        });

        pb.off('click').on('click', (e) => {
            e.stopImmediatePropagation();
            var pbi = $("#pauseIcon");
            console.log('clicked on pause!');

            console.log('paused variable is', paused);

            if (!paused){
                paused = true;
                pbi.removeClass("fa-play-circle");
                pbi.addClass("fa-pause-circle");
                oldmute = mute;
                setMute(true);
            } else {
                paused = false;
                pbi.removeClass("fa-pause-circle");
                pbi.addClass("fa-play-circle");
                setMute(oldmute);
            }
        });

        buffer.onaudioprocess = (ape) => {
            framecount++;
            if (!unruptEnabled) {
                console.log('unrupt isnt enabled so clearing the backlog numbers');
                backlog_sil = backlog_spk = 0;
                return;
            }

            var inputBuffer = ape.inputBuffer;
            // The output buffer contains the samples that will be modified and played
            var outputBuffer = ape.outputBuffer;

            // Loop through the output channels (in this case there is only one)
            if (inputBuffer.numberOfChannels == 1){
                var inputData = inputBuffer.getChannelData(0);
                var outputData = outputBuffer.getChannelData(0);

                // we (almost) always stash the inbound data
                if (audiostash.length < properties.maxStashFrames) {
                    var buff = new Float32Array(inputBuffer.length);
                    var avg = 0.0;

                    for (var sample = 0; sample < inputBuffer.length; sample++) {
                        buff[sample] = inputData[sample]; // copy
                        avg += Math.abs(buff[sample]); // sample
                    }
                    avg = avg / inputBuffer.length;
                    var silent =   (avg  < properties.farSilenceThreshold);
                    if (silent){
                        silentcount++;
                        backlog_sil++;
                    } else {
                        silentcount =0;
                        backlog_spk++;
                    }
                    audiostash.unshift({silent: silent, buff:buff, silentcount: silentcount});
                    // store annotated version
                }
                backlog = audiostash.length /10;
                if (paused || iamspeaking) {
                    for (var sample = 0; sample < inputBuffer.length; sample++) {
                        outputData[sample] = 0.0; // silence
                    }
                } else {
                    var stash = audiostash.pop();
                    if (stash.silent){
                        backlog_sil--;
                    } else {
                        backlog_spk--;
                    }

                    var deleteme = (stash.silent);

                    while ((audiostash.length > 0) && (deleteme)){
                        console.log("have backlog", audiostash.length);
                        deleteme = false;
                        if (audiostash[0].silent){
                            console.log("next one is silent too");
                            if (stash.silentcount > properties.minFramesSilenceForPlay){
                                console.log("silentcount = ", stash.silentcount);
                                deleteme = true;
                                stash = audiostash.pop();
                                if (stash.silent){
                                    backlog_sil--;
                                } else {
                                    backlog_spk--;
                                }
                            }
                        }
                    }
                    var buff = stash.buff;
                    for (var sample = 0; sample < inputBuffer.length; sample++) {
                        outputData[sample] = buff[sample];
                    }
                }
            }
        };
        node.connect(buffer);
        procs.push(buffer)
        return buffer;
    }

    // mute management
    function setMute(m){
        var mi = $("#muteIcon");
        mute = m;
        if (m){
            mi.removeClass("fa-microphone");
            mi.addClass("fa-microphone-slash");
        } else {
            mi.removeClass("fa-microphone-slash");
            mi.addClass("fa-microphone");
        }
        var audioTracks = localStream.getAudioTracks();
        if (audioTracks[0]) {
            audioTracks[0].enabled = !m;
        }
    }

    // processing audio from the local microphone
    function myProc(node){
        var mb = $("#mute");
        mb.click( () => {
            setMute(!mute);
        });
        var buffer = myBuffer;
        console.log("made unrupt buffer of size ", buffer.bufferSize);
        var silentcount = 0;
        buffer.onaudioprocess = ape => {
            var inputBuffer = ape.inputBuffer;

            var outputBuffer = ape.outputBuffer;

            // Loop through the output channels (in this case there is only one)
            if (inputBuffer.numberOfChannels == 1){
                var inputData = inputBuffer.getChannelData(0);
                var outputData = outputBuffer.getChannelData(0);
                // Loop through the 4096 samples
                var avg = 0.0;

                for (var sample = 0; sample < inputBuffer.length; sample++) {
                    // make output equal to the same as the input
                    outputData[sample] = inputData[sample];
                    avg += Math.abs(outputData[sample]); // sample
                }
                avg = avg / inputBuffer.length;
                var silent =   (avg  < properties.micSilenceThreshold);
                if (iamspeaking){
                    if (silent){
                        silentcount++;
                    }
                    if (silentcount > properties.minFramesSilenceForPause){
                        iamspeaking = false;
                    }
                } else {
                    if (!silent) {
                        iamspeaking = true;
                        silentcount =0;
                    }
                }
            }
        };
        node.connect(buffer);
        procs.push(buffer);
        return buffer;
    }

    // called when webRTC presents us with a fresh remote audio stream
    function addStream(stream,kind) {
        if (!kind) {
            kind = "audio/video";
        }

        console.log("got new stream" + stream + " kind =" + kind);
        if (kind.indexOf("video") != -1) {
            remoteStream = stream;
            var mediaElement = document.getElementById('out');
            mediaElement.srcObject = stream;
            //mediaElement.muted = true;
            console.log('Video stream');

            mediaElement.onloadedmetadata = function (e) {
                //mediaElement.play();
                mediaElement.muted = true;
            };
        }
        if (kind.indexOf("audio")!= -1) {
            var peer = yourac.createMediaStreamSource(stream);

            console.log('Audio sample Rate is '+ yourac.sampleRate);

            var scope = doScopeNode(yourac, peer, "farscope");
            var buffproc = yourProc(scope);
            var scope2 = doScopeNode(yourac, buffproc, "earscope");
            scope2.connect(yourac.destination);
            //$("#chosenAction").show();
        }
    }

    // configure local peerconnection and handlers
    function setupRTC(){
        pc = new RTCPeerConnection(webRTCconfiguration, null);
        console.log("created peer connection");

        pc.onicecandidate = (e) => {
            console.log("local ice candidate", e.candidate);
            if (e.candidate != null) {
                if (pc.signalingState == 'stable') {
                    sendMessage(fid, mid, "candidate", e.candidate.candidate);
                } else {
                    console.log("stashing ice candidate");
                    lcandyStash.push(e.candidate);
                }
            }
        };
        pc.oniceconnectionstatechange = (e) => {
            console.log("ice state is changed", pc.iceConnectionState);
            if (pc.iceConnectionState === "failed"){
                stopCall();
            }
        };
        // specification of WEBRTC is in flux - so we test to see if ontrack callback exists
        if ('ontrack' in pc) {
            // if so we use it
            pc.ontrack = (event) => {
                var stream = event.streams[0];
                console.log("got remote track ", event.track.kind);
                addStream(stream,event.track.kind);
            };
        } else {
            // if not we use add stream instead
            pc.onaddstream = (event) => {
                var stream = event.stream;
                console.log("got remote stream ", stream.kind);
                addStream(stream);
            }
        }

        // use this to determine the state of the 'hangup' button and send any candidates we found quickly
        pc.onsignalingstatechange = (evt) => {
            console.log("signalling state is ", pc.signalingState);
            if (pc.signalingState == 'stable') {
                var can;
                while (can = lcandyStash.pop()) {
                    console.log("popping candidate off stash")
                    sendMessage(fid, mid, "candidate", can.candidate);
                }
                var act = $("#action");
                //act.text("hangup");
                act.click( _ => stopCall() );
            }
        };
    }

    // plumb the local audio together.
    function setupAudio() {

        myac = new AudioContext();
        yourac = new AudioContext();

        yourBuffer = yourac.createScriptProcessor(properties.procFramesize, 1, 1);
        myBuffer = myac.createScriptProcessor(properties.procFramesize, 1, 1);
        let supportedConstraints = navigator.mediaDevices.getSupportedConstraints();
        console.log("Supported constraints");
        for (let constraint in supportedConstraints) {
            if (supportedConstraints.hasOwnProperty(constraint)) {
                console.log("\t" + constraint + "=" + supportedConstraints[constraint]);
            }
        }
        //var gumConstraints = {audio: true, video: videoEnabled ? {width: 640, height: 480} : false};
        var gumConstraints = {audio: true, video: true};

        var promise = new Promise(function (resolve, reject) {

            navigator.mediaDevices.getUserMedia(gumConstraints)
                .then((stream) => {
                    localStream = stream; // in case we need it
                    var node = myac.createMediaStreamSource(stream);
                    var detect = myProc(node);
                    var manl = doScopeNode(myac, detect, "nearscope");
//                var dest = myac.createMediaStreamDestination();
//                manl.connect(dest);
//                var lstream = dest.stream;
                    if (pc.addTrack) {
                        stream.getTracks().forEach(track => {
                            pc.addTrack(track, stream);
                            console.log("added local track ", track.id, track.kind);
                        });
                    } else {
                        pc.addStream(stream);
                        console.log("added local stream");
                    }
                    if (videoEnabled) {
                        var ourMediaElement = document.getElementById('in');
                        ourMediaElement.srcObject = stream;

                        ourMediaElement.onloadedmetadata = function (e) {
                            //ourMediaElement.play();
                        };
                        ourMediaElement.onclick = function (e) {
                            console.log("onclick for in video");
                            ourMediaElement.play();
                            var theirMediaElement = document.getElementById('out');
                            theirMediaElement.play();
                        };
                    }
                    resolve(videoEnabled);
                })
                .catch((e) => {
                    console.log('getUserMedia() error:' + e);
                    reject(e);
                });
        });
        return promise;

    }

    function doPlay() {
        var ourMediaElement = document.getElementById('in');

        console.log("onclick for in video");
        ourMediaElement.play();
        var theirMediaElement = document.getElementById('out');
        theirMediaElement.play();
    }


    function shared() {
        setupRTC();
        setupAudio().then(_ => {
            console.log("ready for offer");
            doPlay();

        });
    }
    function accepted() {
        setupRTC();
        setupAudio().then(_ => {
            console.log("ready for offer");
            startCall(cid)
            doPlay();
        });
    }
    // decide who we are initiator or recpient.
    // notice that the actual call goes in the reverse direction
    // the recipient of the invite actually creates the audiobearing peerconnection
    // the initiator then accepts this audio - This allows the initiator the chance to
    // change their mind, if their circumstances have changed since the invite was sent.

    function setRole() {
        cid = $.getUrlVar("unruptId");
        mid = localStorage['unruptId'];
        console.log('URL unrupt ID:', cid);
        console.log('localStorage unrupt ID:', mid);
        //var act = $("#action");
        if (!mid) {
            var array = new Uint32Array(8);
            window.crypto.getRandomValues(array);
            var hexCodes = [];
            for (var i = 0; i < array.length; i ++ ){
                // Using getUint32 reduces the number of iterations needed (we process 4 bytes each time)
                var value = array[i];
                // toString(16) will give the hex representation of the number without padding
                var stringValue = value.toString(16)
                // We use concatenation and slice for padding
                var padding = '00000000'
                var paddedValue = (padding + stringValue).slice(-padding.length)
                hexCodes.push(paddedValue);
            }
            mid = hexCodes.join("").toLowerCase();
            localStorage['unruptId'] = mid;
            console.log('Didnt have our own unrupt ID so generated one:', mid);
        }
        if (cid == null){
            chooseAction.show();
            chooseActionAudio.click( _ => {
                document.location = location.pathname + "?" + "unruptId=" + mid;
            });
            chooseActionVideo.click( _ => {
                document.location = location.pathname + "?" + "unruptId=" + mid + "&video=1";
            });
        } else {
            var qrcode = new QRCode(document.getElementById("shareQR"), {
                width: 280,
                height: 280,
                correctLevel: QRCode.CorrectLevel.L
            });
            socket = new WebSocket( properties.websocketURL + mid);
            socket.onmessage = messageDeal;
            socket.onopen = (_) => {
                var url = document.location.href;
                console.log("href = "+url);
                if (url) {
                    qrcode.makeCode(url);
                }
                initiator = (mid === cid);
                console.log(initiator ? 'We are the initiator' : 'We are not the initiator');
                var smodal = initiator ? "#share":"#accept";
                $(smodal).modal('show');
            };
            socket.onerror = (e) => {
                console.log("can't open websocket", e);
            };
            socket.onclose = (e) => {
                console.log(" websocket closed", e);
            };

        }
    }

    // thing that draws the scopes...
    function makeDraw(canvName, anode) {
        var analyser = anode;
        var speaking = false;
        var bufferLength = analyser.frequencyBinCount;
        var dataArray = new Uint8Array(bufferLength);
        var canvas = document.getElementById(canvName);
        var badge = document.getElementById(canvName + "-badge");
        if ((badge) && (canvas)) {
            var canvasCtx = canvas.getContext("2d");
// oscilloscope - for debug.
            var draw = _ => {
// Get a canvas defined with ID "oscilloscope"
                var drawVisual = requestAnimationFrame(draw);

                analyser.getByteTimeDomainData(dataArray);

                canvasCtx.fillStyle = 'rgb(200, 200, 200)';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

                canvasCtx.lineWidth = 2;
                canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

                canvasCtx.beginPath();

                var sliceWidth = canvas.width * 1.0 / bufferLength;
                var x = 0;
                var tot = 0.0;

                for (var i = 0; i < bufferLength; i++) {


                    var v = dataArray[i] / 128.0;
                    tot += Math.abs(dataArray[i] - 128);
                    var y = v * canvas.height / 2;

                    if (i === 0) {
                        canvasCtx.moveTo(x, y);
                    } else {
                        canvasCtx.lineTo(x, y);
                    }

                    x += sliceWidth;
                }
                var mean = tot / bufferLength;
                var newspeak = (mean > 2.0);
                if (newspeak != speaking) {
                    speaking = newspeak;
                    //console.log("newspeak "+newspeak+" mean "+mean);
                    badge.innerText = speaking ? "Speaking" : "Silent";
                }
                canvasCtx.lineTo(canvas.width, canvas.height / 2);
                canvasCtx.stroke();
            };
            draw();
        }
    }



    // some housekeeping

    $.extend({
        getUrlVars: function(){
            var vars = [], hash;
            var hashes = window.location.href.slice(window.location.href.indexOf('?') + 1).split('&');
            for(var i = 0; i < hashes.length; i++)
            {
                hash = hashes[i].split('=');
                vars.push(hash[0]);
                vars[hash[0]] = hash[1];
            }
            return vars;
        },
        getUrlVar: function(name){
            return $.getUrlVars()[name];
        }
    });

    $( document ).ready( _ => {
        videoEnabled = $.getUrlVar("video") == '1';

        if(videoEnabled) {
            peerConnectionOfferAnswerCriteria = {};
            var otherUserMediaElement = document.createElement('video');
            otherUserMediaElement.id = 'out';
            otherUserMediaElement.muted = true;
            otherUserMediaElement.className ="video";
            otherUserMediaElement.setAttribute("playsinline", "true");
            //otherUserMediaElement.setAttribute("autoplay", "true");


            document.getElementById('otherUser').appendChild(otherUserMediaElement);

            var thisUserMediaElement = document.createElement('video');
            thisUserMediaElement.id = 'in';
            thisUserMediaElement.muted = true;
            thisUserMediaElement.setAttribute("playsinline", "true");
            //thisUserMediaElement.setAttribute("autoplay", "true");


            document.getElementById('otherUser').appendChild(thisUserMediaElement);


        } else {
            var mediaElement = document.createElement('audio');
            mediaElement.id = 'out';
            mediaElement.muted = true;
            document.body.appendChild(mediaElement);
        }
        //$("#chosenAction").hide();
        setRole();

        //$('#version').text(properties.versionname);
        tick = window.setInterval( t => {
            var scale = properties.maxStashFrames / 100.0;
            var spk = backlog_spk / scale;
            var sil = backlog_sil / scale;
            var timeline = Math.floor((backlog_spk + backlog_sil) * properties.procFramesize / 44100.0);
            $('#unruptbuffer_len').text(timeline + " seconds");
            $('#unruptbuffer_sil').css('width', sil + "%").attr('aria-valuenow', sil);
            $('#unruptbuffer_spk').css('width', spk + "%").attr('aria-valuenow', spk);
            var playout = backlog > 1 ? "playing" : "direct";
            var newmode = (iamspeaking || paused) ? "paused" : playout;
            if (newmode != mode) {
                if (remoteStream && videoEnabled && unruptEnabled) {
                    mode = newmode;
                    $('#mode').text(mode);
                    var pauseIcon = $('#pauseOther');
                    var pause = false;
                    if (mode === "paused") {
                        //otherUserMediaElement.pause();
                        //videoCapture();
                        pauseIcon.show();
                        //$('#out').hide();
                        pause = true;
                    } else {
                        //otherUserMediaElement.play();
                        pauseIcon.hide();
                        //$('#out').show();
                    }
                    // ideally if this is pause-start, we'd snapshot the video and pull a still
                    //otherUserMediaElement.srcObject.getTracks().forEach(t => t.enabled = !pause);
                }
            }
        }, 250);
    });
</script>
</body>
</html>
